{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import random\n",
    "from random import uniform\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from skimage.feature import hog\n",
    "from sklearn import tree\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel1015</th>\n",
       "      <th>pixel1016</th>\n",
       "      <th>pixel1017</th>\n",
       "      <th>pixel1018</th>\n",
       "      <th>pixel1019</th>\n",
       "      <th>pixel1020</th>\n",
       "      <th>pixel1021</th>\n",
       "      <th>pixel1022</th>\n",
       "      <th>pixel1023</th>\n",
       "      <th>pixel1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "1        12       0       0       0       0       0       0       0       0   \n",
       "2        22       0       0       0       0       0       0       0       0   \n",
       "3        16       0       0       0       0       0       0       0       0   \n",
       "4         1       0       0       0       0       0       0       0       0   \n",
       "5         2       0       0       0       0       0       0       0       0   \n",
       "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "1696      1       0       0       0       0       0       0       0       0   \n",
       "1697     12       0       0       0       0       0       0       0       0   \n",
       "1698     22       0       0       0       0       0       0       0       0   \n",
       "1699     12       0       0       0       0       0       0       0       0   \n",
       "1700     16       0       0       0       0       0       0       0       0   \n",
       "\n",
       "      pixel9  ...  pixel1015  pixel1016  pixel1017  pixel1018  pixel1019  \\\n",
       "1          0  ...          0          0          0          0          0   \n",
       "2          0  ...          0          0          0          0          0   \n",
       "3          0  ...          0          0          0          0          0   \n",
       "4          0  ...          0          0          0          0          0   \n",
       "5          0  ...          0          0          0          0          0   \n",
       "...      ...  ...        ...        ...        ...        ...        ...   \n",
       "1696       0  ...          0          0          0          0          0   \n",
       "1697       0  ...          0          0          0          0          0   \n",
       "1698       0  ...          0          0          0          0          0   \n",
       "1699       0  ...          0          0          0          0          0   \n",
       "1700       0  ...          0          0          0          0          0   \n",
       "\n",
       "      pixel1020  pixel1021  pixel1022  pixel1023  pixel1024  \n",
       "1             0          0          0          0          0  \n",
       "2             0          0          0          0          0  \n",
       "3             0          0          0          0          0  \n",
       "4             0          0          0          0          0  \n",
       "5             0          0          0          0          0  \n",
       "...         ...        ...        ...        ...        ...  \n",
       "1696          0          0          0          0          0  \n",
       "1697          0          0          0          0          0  \n",
       "1698          0          0          0          0          0  \n",
       "1699          0          0          0          0          0  \n",
       "1700          0          0          0          0          0  \n",
       "\n",
       "[1700 rows x 1025 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the main dataset and print it\n",
    "dataset = pd.read_csv('./arabic_dataset.csv', delimiter=\";\", index_col=0)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the competition set and print it\n",
    "competition = pd.read_csv('./competition.csv', delimiter=\";\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel1015</th>\n",
       "      <th>pixel1016</th>\n",
       "      <th>pixel1017</th>\n",
       "      <th>pixel1018</th>\n",
       "      <th>pixel1019</th>\n",
       "      <th>pixel1020</th>\n",
       "      <th>pixel1021</th>\n",
       "      <th>pixel1022</th>\n",
       "      <th>pixel1023</th>\n",
       "      <th>pixel1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "1         0       0       0       0       0       0       0       0       0   \n",
       "2         0       0       0       0       0       0       0       0       0   \n",
       "3         0       0       0       0       0       0       0       0       0   \n",
       "4         0       0       0       0       0       0       0       0       0   \n",
       "5         0       0       0       0       0       0       0       0       0   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "496       0       0       0       0       0       0       0       0       0   \n",
       "497       0       0       0       0       0       0       0       0       0   \n",
       "498       0       0       0       0       0       0       0       0       0   \n",
       "499       0       0       0       0       0       0       0       0       0   \n",
       "500       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "     pixel10  ...  pixel1015  pixel1016  pixel1017  pixel1018  pixel1019  \\\n",
       "1          0  ...          0          0          0          0          0   \n",
       "2          0  ...          0          0          0          0          0   \n",
       "3          0  ...          0          0          0          0          0   \n",
       "4          0  ...          0          0          0          0          0   \n",
       "5          0  ...          0          0          0          0          0   \n",
       "..       ...  ...        ...        ...        ...        ...        ...   \n",
       "496        0  ...          0          0          0          0          0   \n",
       "497        0  ...          0          0          0          0          0   \n",
       "498        0  ...          0          0          0          0          0   \n",
       "499        0  ...          0          0          0          0          0   \n",
       "500        0  ...          0          0          0          0          0   \n",
       "\n",
       "     pixel1020  pixel1021  pixel1022  pixel1023  pixel1024  \n",
       "1            0          0          0          0          0  \n",
       "2            0          0          0          0          0  \n",
       "3            0          0          0          0          0  \n",
       "4            0          0          0          0          0  \n",
       "5            0          0          0          0          0  \n",
       "..         ...        ...        ...        ...        ...  \n",
       "496          0          0          0          0          0  \n",
       "497          0          0          0          0          0  \n",
       "498          0          0          0          0          0  \n",
       "499          0          0          0          0          0  \n",
       "500          0          0          0          0          0  \n",
       "\n",
       "[500 rows x 1024 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competition\n",
    "# You should see that there are no labels in this dataset. You'll have to predict them.\n",
    "# So this dataset can not be used to fit any classifier, just to make predictions with classifiers that you designed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17f143530>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here you can see the image 0 of the dataset\n",
    "idx = 0\n",
    "plt.imshow(dataset.iloc[idx,1:].to_numpy().reshape(32,32),cmap = 'Greys')\n",
    "# you can change the value of idx if you want to see another image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17f5f4770>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Same with the image 0 of competition\n",
    "idx = 0\n",
    "plt.imshow(competition.iloc[idx,:].to_numpy().reshape(32,32),cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First guided submission to Kaggle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I will show you here how to submit your predictions on Kaggle. We will generate random predictions of the competition set but then you will predict these labels with classifiers that you designed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16,\n",
       " 2,\n",
       " 2,\n",
       " 18,\n",
       " 6,\n",
       " 18,\n",
       " 12,\n",
       " 1,\n",
       " 16,\n",
       " 16,\n",
       " 22,\n",
       " 22,\n",
       " 16,\n",
       " 1,\n",
       " 2,\n",
       " 16,\n",
       " 18,\n",
       " 12,\n",
       " 12,\n",
       " 22,\n",
       " 22,\n",
       " 2,\n",
       " 18,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 22,\n",
       " 16,\n",
       " 12,\n",
       " 12,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 22,\n",
       " 16,\n",
       " 18,\n",
       " 1,\n",
       " 2,\n",
       " 18,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 18,\n",
       " 2,\n",
       " 1,\n",
       " 18,\n",
       " 18,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 12,\n",
       " 6,\n",
       " 12,\n",
       " 22,\n",
       " 22,\n",
       " 18,\n",
       " 6,\n",
       " 18,\n",
       " 6,\n",
       " 22,\n",
       " 6,\n",
       " 16,\n",
       " 18,\n",
       " 18,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 12,\n",
       " 22,\n",
       " 22,\n",
       " 6,\n",
       " 1,\n",
       " 18,\n",
       " 22,\n",
       " 2,\n",
       " 18,\n",
       " 16,\n",
       " 16,\n",
       " 18,\n",
       " 18,\n",
       " 6,\n",
       " 22,\n",
       " 18,\n",
       " 16,\n",
       " 1,\n",
       " 2,\n",
       " 22,\n",
       " 1,\n",
       " 16,\n",
       " 1,\n",
       " 18,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 12,\n",
       " 16,\n",
       " 22,\n",
       " 12,\n",
       " 12,\n",
       " 18,\n",
       " 12,\n",
       " 16,\n",
       " 16,\n",
       " 6,\n",
       " 12,\n",
       " 6,\n",
       " 2,\n",
       " 16,\n",
       " 22,\n",
       " 6,\n",
       " 16,\n",
       " 22,\n",
       " 12,\n",
       " 2,\n",
       " 1,\n",
       " 18,\n",
       " 18,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 18,\n",
       " 12,\n",
       " 1,\n",
       " 22,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 1,\n",
       " 18,\n",
       " 1,\n",
       " 18,\n",
       " 6,\n",
       " 18,\n",
       " 12,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 22,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 22,\n",
       " 1,\n",
       " 1,\n",
       " 18,\n",
       " 1,\n",
       " 22,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 2,\n",
       " 18,\n",
       " 22,\n",
       " 22,\n",
       " 16,\n",
       " 18,\n",
       " 18,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 16,\n",
       " 2,\n",
       " 18,\n",
       " 1,\n",
       " 1,\n",
       " 22,\n",
       " 18,\n",
       " 22,\n",
       " 12,\n",
       " 2,\n",
       " 16,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 18,\n",
       " 22,\n",
       " 12,\n",
       " 18,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 18,\n",
       " 2,\n",
       " 22,\n",
       " 16,\n",
       " 16,\n",
       " 12,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 16,\n",
       " 1,\n",
       " 12,\n",
       " 18,\n",
       " 12,\n",
       " 16,\n",
       " 18,\n",
       " 16,\n",
       " 2,\n",
       " 6,\n",
       " 12,\n",
       " 1,\n",
       " 6,\n",
       " 12,\n",
       " 1,\n",
       " 18,\n",
       " 16,\n",
       " 12,\n",
       " 16,\n",
       " 16,\n",
       " 18,\n",
       " 12,\n",
       " 12,\n",
       " 22,\n",
       " 12,\n",
       " 12,\n",
       " 22,\n",
       " 1,\n",
       " 2,\n",
       " 18,\n",
       " 12,\n",
       " 1,\n",
       " 12,\n",
       " 2,\n",
       " 22,\n",
       " 2,\n",
       " 18,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 18,\n",
       " 6,\n",
       " 12,\n",
       " 18,\n",
       " 22,\n",
       " 1,\n",
       " 2,\n",
       " 12,\n",
       " 12,\n",
       " 16,\n",
       " 12,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 22,\n",
       " 1,\n",
       " 12,\n",
       " 12,\n",
       " 6,\n",
       " 12,\n",
       " 12,\n",
       " 16,\n",
       " 6,\n",
       " 12,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 22,\n",
       " 18,\n",
       " 6,\n",
       " 12,\n",
       " 2,\n",
       " 12,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 12,\n",
       " 12,\n",
       " 18,\n",
       " 12,\n",
       " 22,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 1,\n",
       " 22,\n",
       " 1,\n",
       " 12,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 16,\n",
       " 6,\n",
       " 12,\n",
       " 22,\n",
       " 22,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 16,\n",
       " 12,\n",
       " 2,\n",
       " 2,\n",
       " 18,\n",
       " 18,\n",
       " 12,\n",
       " 12,\n",
       " 18,\n",
       " 2,\n",
       " 16,\n",
       " 18,\n",
       " 18,\n",
       " 2,\n",
       " 1,\n",
       " 18,\n",
       " 6,\n",
       " 18,\n",
       " 16,\n",
       " 2,\n",
       " 1,\n",
       " 12,\n",
       " 6,\n",
       " 1,\n",
       " 22,\n",
       " 6,\n",
       " 22,\n",
       " 16,\n",
       " 18,\n",
       " 16,\n",
       " 2,\n",
       " 22,\n",
       " 16,\n",
       " 6,\n",
       " 12,\n",
       " 18,\n",
       " 2,\n",
       " 1,\n",
       " 16,\n",
       " 22,\n",
       " 6,\n",
       " 1,\n",
       " 18,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 18,\n",
       " 16,\n",
       " 18,\n",
       " 1,\n",
       " 12,\n",
       " 1,\n",
       " 2,\n",
       " 22,\n",
       " 1,\n",
       " 18,\n",
       " 22,\n",
       " 2,\n",
       " 1,\n",
       " 16,\n",
       " 12,\n",
       " 1,\n",
       " 22,\n",
       " 18,\n",
       " 18,\n",
       " 16,\n",
       " 12,\n",
       " 1,\n",
       " 12,\n",
       " 2,\n",
       " 6,\n",
       " 16,\n",
       " 12,\n",
       " 12,\n",
       " 22,\n",
       " 2,\n",
       " 2,\n",
       " 18,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 16,\n",
       " 12,\n",
       " 18,\n",
       " 22,\n",
       " 12,\n",
       " 22,\n",
       " 16,\n",
       " 18,\n",
       " 16,\n",
       " 18,\n",
       " 18,\n",
       " 1,\n",
       " 18,\n",
       " 6,\n",
       " 12,\n",
       " 18,\n",
       " 6,\n",
       " 1,\n",
       " 12,\n",
       " 6,\n",
       " 22,\n",
       " 1,\n",
       " 22,\n",
       " 18,\n",
       " 18,\n",
       " 12,\n",
       " 1,\n",
       " 12,\n",
       " 1,\n",
       " 22,\n",
       " 12,\n",
       " 1,\n",
       " 1,\n",
       " 16,\n",
       " 12,\n",
       " 18,\n",
       " 16,\n",
       " 16,\n",
       " 18,\n",
       " 6,\n",
       " 22,\n",
       " 18,\n",
       " 22,\n",
       " 12,\n",
       " 12,\n",
       " 22,\n",
       " 18,\n",
       " 22,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 18,\n",
       " 2,\n",
       " 22,\n",
       " 18,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 22,\n",
       " 16,\n",
       " 18,\n",
       " 22,\n",
       " 16,\n",
       " 16,\n",
       " 18,\n",
       " 1,\n",
       " 18,\n",
       " 12,\n",
       " 12,\n",
       " 1,\n",
       " 2,\n",
       " 18,\n",
       " 1,\n",
       " 18,\n",
       " 2,\n",
       " 6,\n",
       " 18,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 12,\n",
       " 2,\n",
       " 22,\n",
       " 22,\n",
       " 1,\n",
       " 18,\n",
       " 18,\n",
       " 6,\n",
       " 2,\n",
       " 12,\n",
       " 18,\n",
       " 12,\n",
       " 12,\n",
       " 18,\n",
       " 2,\n",
       " 6,\n",
       " 12,\n",
       " 16,\n",
       " 22,\n",
       " 22,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 16,\n",
       " 2,\n",
       " 18,\n",
       " 18,\n",
       " 18]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "pred = random.choices(np.unique(dataset.label), k=500)\n",
    "pred\n",
    "# pred is a vector with 500 random values from the set of possible label values \n",
    "# we will assume that these are our 500 predictions for the competition set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  label\n",
       "0      1     16\n",
       "1      2      2\n",
       "2      3      2\n",
       "3      4     18\n",
       "4      5      6\n",
       "..   ...    ...\n",
       "495  496     16\n",
       "496  497      2\n",
       "497  498     18\n",
       "498  499     18\n",
       "499  500     18\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we put this predictions in a DataFrame with the right format expected by kaggle\n",
    "df = pd.DataFrame(np.arange(1,501), columns=['Id'])\n",
    "df['label'] = pred\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# then save it to a csv file\n",
    "df.to_csv('myfirstsubmission.csv', index=False)\n",
    "# You should now have a csv file on your working directory\n",
    "# Go on Kaggle website, join the competition and drag this file into 'Submit predictions'. You should have a score\n",
    "# This score might not be high because we have just done random predictions\n",
    "# but when you'll design classifiers and make more clever predictions you will improve your score\n",
    "# Later, when you'll have found an interesting classifier for each family, you have to predict the competition set\n",
    "# with this classifier, put these predictions into a vector (like pred above) and apply the same procedure as\n",
    "# in the previous cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : preliminar analysis of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse univariÃ©e patrtielle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1700 entries, 1 to 1700\n",
      "Columns: 1025 entries, label to pixel1024\n",
      "dtypes: int64(1025)\n",
      "memory usage: 13.3 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commentaire 1\n",
    "On constate ici que nous avons 1700 entrÃ©es, une variable cible \"label\" et 1024 descripteurs\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "12    0.150000\n",
      "6     0.147059\n",
      "22    0.144118\n",
      "18    0.141765\n",
      "1     0.140000\n",
      "2     0.140000\n",
      "16    0.137059\n",
      "Name: proportion, dtype: float64\n",
      "label\n",
      "12    255\n",
      "6     250\n",
      "22    245\n",
      "18    241\n",
      "1     238\n",
      "2     238\n",
      "16    233\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset['label'].value_counts(normalize=True))\n",
    "print(dataset['label'].value_counts(normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commentaire 2\n",
    "Notre variable cible \"label\" est subdivisÃ© en 7 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label        0\n",
       "pixel1       0\n",
       "pixel2       0\n",
       "pixel3       0\n",
       "pixel4       0\n",
       "            ..\n",
       "pixel1020    0\n",
       "pixel1021    0\n",
       "pixel1022    0\n",
       "pixel1023    0\n",
       "pixel1024    0\n",
       "Length: 1025, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel1015</th>\n",
       "      <th>pixel1016</th>\n",
       "      <th>pixel1017</th>\n",
       "      <th>pixel1018</th>\n",
       "      <th>pixel1019</th>\n",
       "      <th>pixel1020</th>\n",
       "      <th>pixel1021</th>\n",
       "      <th>pixel1022</th>\n",
       "      <th>pixel1023</th>\n",
       "      <th>pixel1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.017647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.002353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.550554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041984</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>0.034290</td>\n",
       "      <td>0.024254</td>\n",
       "      <td>0.034290</td>\n",
       "      <td>0.048464</td>\n",
       "      <td>0.048464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "count  1700.000000  1700.0  1700.0  1700.0  1700.0  1700.0  1700.0  1700.0   \n",
       "mean     11.017647     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "std       7.550554     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "min       1.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "25%       2.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "50%      12.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "75%      18.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "max      22.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel8  pixel9  ...  pixel1015    pixel1016  pixel1017    pixel1018  \\\n",
       "count  1700.0  1700.0  ...     1700.0  1700.000000     1700.0  1700.000000   \n",
       "mean      0.0     0.0  ...        0.0     0.001176        0.0     0.001765   \n",
       "std       0.0     0.0  ...        0.0     0.034290        0.0     0.041984   \n",
       "min       0.0     0.0  ...        0.0     0.000000        0.0     0.000000   \n",
       "25%       0.0     0.0  ...        0.0     0.000000        0.0     0.000000   \n",
       "50%       0.0     0.0  ...        0.0     0.000000        0.0     0.000000   \n",
       "75%       0.0     0.0  ...        0.0     0.000000        0.0     0.000000   \n",
       "max       0.0     0.0  ...        0.0     1.000000        0.0     1.000000   \n",
       "\n",
       "         pixel1019    pixel1020    pixel1021    pixel1022    pixel1023  \\\n",
       "count  1700.000000  1700.000000  1700.000000  1700.000000  1700.000000   \n",
       "mean      0.002941     0.001176     0.000588     0.001176     0.002353   \n",
       "std       0.054169     0.034290     0.024254     0.034290     0.048464   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         pixel1024  \n",
       "count  1700.000000  \n",
       "mean      0.002353  \n",
       "std       0.048464  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 1025 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#description description des donnÃ©es\n",
    "dataset.describe(include=('all'))# De la "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commentaire 3\n",
    "Nous n'avons pas de valeur nulle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : classifiers based on raw images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Valid / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel1015</th>\n",
       "      <th>pixel1016</th>\n",
       "      <th>pixel1017</th>\n",
       "      <th>pixel1018</th>\n",
       "      <th>pixel1019</th>\n",
       "      <th>pixel1020</th>\n",
       "      <th>pixel1021</th>\n",
       "      <th>pixel1022</th>\n",
       "      <th>pixel1023</th>\n",
       "      <th>pixel1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "248       6       0       0       0       0       0       0       0       0   \n",
       "436      16       0       0       0       0       0       0       0       0   \n",
       "1507     16       0       0       0       0       0       0       0       0   \n",
       "1134      1       0       0       0       0       0       0       0       0   \n",
       "1291     12       0       0       0       0       0       0       0       0   \n",
       "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "361      22       0       0       0       0       0       0       0       0   \n",
       "710      12       0       0       0       0       0       0       0       0   \n",
       "440      22       0       0       0       0       0       0       0       0   \n",
       "175       6       0       0       0       0       0       0       0       0   \n",
       "1147     18       0       0       0       0       0       0       0       0   \n",
       "\n",
       "      pixel9  ...  pixel1015  pixel1016  pixel1017  pixel1018  pixel1019  \\\n",
       "248        0  ...          0          0          0          0          0   \n",
       "436        0  ...          0          0          0          0          0   \n",
       "1507       0  ...          0          0          0          0          0   \n",
       "1134       0  ...          0          0          0          0          0   \n",
       "1291       0  ...          0          0          0          0          0   \n",
       "...      ...  ...        ...        ...        ...        ...        ...   \n",
       "361        0  ...          0          0          0          0          0   \n",
       "710        0  ...          0          0          0          0          0   \n",
       "440        0  ...          0          0          0          0          0   \n",
       "175        0  ...          0          0          0          0          0   \n",
       "1147       0  ...          0          0          0          0          0   \n",
       "\n",
       "      pixel1020  pixel1021  pixel1022  pixel1023  pixel1024  \n",
       "248           0          0          0          0          0  \n",
       "436           0          0          0          0          0  \n",
       "1507          0          0          0          0          0  \n",
       "1134          0          0          0          0          0  \n",
       "1291          0          0          0          0          0  \n",
       "...         ...        ...        ...        ...        ...  \n",
       "361           0          0          0          0          0  \n",
       "710           0          0          0          0          0  \n",
       "440           0          0          0          0          0  \n",
       "175           0          0          0          0          0  \n",
       "1147          0          0          0          0          0  \n",
       "\n",
       "[1190 rows x 1025 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(dataset, test_size = 0.3, random_state = 4)\n",
    "data_valid, data_test = train_test_split(data_test, test_size = 0.5, random_state = 4)\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation de l'arbre de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basic decision tree can be obtained easily by this command\n",
    "arbre = tree.DecisionTreeClassifier().fit(data_train.iloc[:,1:],data_train.label)\n",
    "# More advanced options can be inserted into the 'DecisionTreeClassifier' function (we will see some later)\n",
    "# The 'fit' function needs to have 2 parameters (at least) : \n",
    "# - the set of features describing the examples (here the 2 first columns of our train set)\n",
    "# - the associated labels (classes, here the column 'Y' of our train set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un aperÃ§u de la perfomances de l'arbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sur le data_train 1.0\n",
      "Sur le data_valid 0.5176470588235295\n",
      "Sur le data_test 0.5098039215686274\n"
     ]
    }
   ],
   "source": [
    "perf_sur_train= arbre.score(data_train.iloc[:,1:],data_train.label)\n",
    "perf_sur_val= arbre.score(data_valid.iloc[:,1:],data_valid.label)\n",
    "perf_sur_test= arbre.score(data_test.iloc[:,1:],data_test.label)\n",
    "\n",
    "print(\"Sur le data_train \"+ str(perf_sur_train))\n",
    "print(\"Sur le data_valid \"+ str(perf_sur_val))\n",
    "print(\"Sur le data_test \"+ str(perf_sur_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nous allons maintenant procÃ©der Ã  l'Ã©lagage de l'arbre ainsi crÃ©Ã© afin de trouver un arbre qui maximise la perfomance sur les donnÃ©es de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 1 (arbre): Calculer le alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alphas': array([0.        , 0.00078031, 0.00078782, 0.00080032, 0.00081487,\n",
       "        0.00081822, 0.00084034, 0.00084034, 0.00084034, 0.00084034,\n",
       "        0.00084034, 0.00084034, 0.00084034, 0.00084034, 0.00084034,\n",
       "        0.00084034, 0.00084034, 0.00084034, 0.00084034, 0.00084034,\n",
       "        0.00084034, 0.00084034, 0.00084034, 0.00084034, 0.00084034,\n",
       "        0.00084034, 0.00084034, 0.00084034, 0.00084034, 0.00084034,\n",
       "        0.00084034, 0.00084034, 0.00084034, 0.00084034, 0.00084034,\n",
       "        0.00112045, 0.00112045, 0.00112045, 0.00112045, 0.00112045,\n",
       "        0.00112045, 0.00112045, 0.00112045, 0.00112045, 0.00112045,\n",
       "        0.00112045, 0.00112045, 0.00112045, 0.00112045, 0.00112045,\n",
       "        0.00112045, 0.00112045, 0.0012605 , 0.0012605 , 0.0012605 ,\n",
       "        0.0012605 , 0.0012605 , 0.0012605 , 0.0012605 , 0.0012605 ,\n",
       "        0.0012605 , 0.0012605 , 0.0012605 , 0.0012605 , 0.0012605 ,\n",
       "        0.0012605 , 0.0012605 , 0.0012605 , 0.0012605 , 0.00130719,\n",
       "        0.00130719, 0.00131702, 0.00134454, 0.00134454, 0.00134454,\n",
       "        0.00134454, 0.00134454, 0.00134454, 0.00134454, 0.00134454,\n",
       "        0.00139186, 0.00140056, 0.00142796, 0.00144058, 0.00144058,\n",
       "        0.00144324, 0.00147059, 0.00149393, 0.00149393, 0.00151261,\n",
       "        0.00151261, 0.00151261, 0.00151261, 0.00151261, 0.00151261,\n",
       "        0.00152311, 0.00152311, 0.00152788, 0.00152788, 0.00154062,\n",
       "        0.00154062, 0.00154511, 0.00154622, 0.00154983, 0.00156062,\n",
       "        0.00156062, 0.00156863, 0.00156863, 0.00157106, 0.00157563,\n",
       "        0.00158331, 0.0015873 , 0.00159222, 0.00159508, 0.00161064,\n",
       "        0.00161345, 0.00162065, 0.00162065, 0.00162272, 0.00162646,\n",
       "        0.00164896, 0.00168067, 0.00168067, 0.00168067, 0.00168067,\n",
       "        0.00168067, 0.00168067, 0.00170868, 0.0017607 , 0.00177404,\n",
       "        0.00180072, 0.00184544, 0.00186617, 0.00187783, 0.00189076,\n",
       "        0.00193532, 0.00194211, 0.00194678, 0.00197246, 0.00198079,\n",
       "        0.00201034, 0.00206252, 0.00207211, 0.00211018, 0.00212369,\n",
       "        0.00213612, 0.00214286, 0.00216309, 0.00220785, 0.00221543,\n",
       "        0.0022409 , 0.0022409 , 0.0022409 , 0.0022449 , 0.00226891,\n",
       "        0.0023276 , 0.00245098, 0.00252101, 0.00252101, 0.00252737,\n",
       "        0.00253394, 0.00256114, 0.00261204, 0.00261723, 0.00264324,\n",
       "        0.00264542, 0.00266106, 0.00267686, 0.00269532, 0.00270558,\n",
       "        0.0027105 , 0.0027521 , 0.00277034, 0.00277111, 0.00277311,\n",
       "        0.00282353, 0.00286533, 0.00288115, 0.00288958, 0.00291507,\n",
       "        0.00294724, 0.00298147, 0.00316467, 0.00319601, 0.00321248,\n",
       "        0.0032413 , 0.00324393, 0.00325094, 0.00327404, 0.00327646,\n",
       "        0.00332853, 0.00333467, 0.00338261, 0.00339097, 0.00351623,\n",
       "        0.00356233, 0.00358252, 0.00366692, 0.00369751, 0.00379798,\n",
       "        0.00384154, 0.00384898, 0.00406657, 0.00407455, 0.00409133,\n",
       "        0.00411014, 0.0041945 , 0.004252  , 0.00427171, 0.0042954 ,\n",
       "        0.00432115, 0.00445378, 0.00450847, 0.00451462, 0.00468223,\n",
       "        0.00470588, 0.00470588, 0.00475771, 0.00481913, 0.00495487,\n",
       "        0.00520466, 0.00577434, 0.00584164, 0.00585397, 0.00585467,\n",
       "        0.00588166, 0.00630119, 0.00641423, 0.00655641, 0.00656537,\n",
       "        0.00665185, 0.00680768, 0.00696849, 0.00827187, 0.0087978 ,\n",
       "        0.00902778, 0.00947779, 0.01003329, 0.01059075, 0.01081506,\n",
       "        0.01091255, 0.01093952, 0.01130371, 0.01215765, 0.01628024,\n",
       "        0.01751413, 0.02112113, 0.02451838]),\n",
       " 'impurities': array([0.        , 0.00156062, 0.00313625, 0.00473689, 0.00636664,\n",
       "        0.00800308, 0.01052409, 0.01220476, 0.0130451 , 0.01388543,\n",
       "        0.01472577, 0.01640644, 0.01724678, 0.01808712, 0.01892745,\n",
       "        0.01976779, 0.02060812, 0.02144846, 0.0222888 , 0.02396947,\n",
       "        0.02649048, 0.02733081, 0.02817115, 0.02901148, 0.03069216,\n",
       "        0.03153249, 0.03237283, 0.03489384, 0.03573417, 0.03657451,\n",
       "        0.03741485, 0.03825518, 0.03909552, 0.03993585, 0.04077619,\n",
       "        0.04189664, 0.04301709, 0.04413754, 0.04525798, 0.04637843,\n",
       "        0.04749888, 0.04861933, 0.04973978, 0.05086022, 0.05310112,\n",
       "        0.05422157, 0.05534202, 0.05646247, 0.05758291, 0.05870336,\n",
       "        0.05982381, 0.06094426, 0.06220476, 0.06346527, 0.06472577,\n",
       "        0.06598627, 0.06724678, 0.06850728, 0.06976779, 0.07102829,\n",
       "        0.0722888 , 0.0735493 , 0.0748098 , 0.07607031, 0.07733081,\n",
       "        0.07859132, 0.07985182, 0.08237283, 0.08363333, 0.08886209,\n",
       "        0.09147647, 0.09279349, 0.09413803, 0.09548256, 0.0968271 ,\n",
       "        0.09817164, 0.09951618, 0.10086072, 0.10220525, 0.10354979,\n",
       "        0.10633351, 0.10773407, 0.10916204, 0.11060261, 0.11204319,\n",
       "        0.11348643, 0.11495702, 0.11943881, 0.12093274, 0.12244535,\n",
       "        0.12395795, 0.12547056, 0.12698316, 0.12849577, 0.13000837,\n",
       "        0.13305459, 0.13610081, 0.1376287 , 0.13915658, 0.1406972 ,\n",
       "        0.14223781, 0.14687315, 0.1515118 , 0.15306163, 0.15618288,\n",
       "        0.1577435 , 0.15931213, 0.16088076, 0.16402289, 0.16559852,\n",
       "        0.16718182, 0.16876912, 0.17036134, 0.17195642, 0.17356707,\n",
       "        0.17518051, 0.17680116, 0.17842181, 0.18004453, 0.18167098,\n",
       "        0.18331995, 0.18500062, 0.18668129, 0.18836196, 0.19004263,\n",
       "        0.19172331, 0.19340398, 0.19511266, 0.19687337, 0.19864741,\n",
       "        0.20044813, 0.20229357, 0.20415974, 0.2079154 , 0.20980615,\n",
       "        0.21174147, 0.21368358, 0.21563036, 0.21760282, 0.21958361,\n",
       "        0.2236043 , 0.22566682, 0.22773893, 0.22984911, 0.2319728 ,\n",
       "        0.24478954, 0.2469324 , 0.25342166, 0.25783736, 0.26448365,\n",
       "        0.26896545, 0.27120634, 0.27344724, 0.27569214, 0.27796104,\n",
       "        0.28494384, 0.28739482, 0.28991583, 0.29243683, 0.29749158,\n",
       "        0.30002552, 0.3051478 , 0.31037189, 0.31560636, 0.3182496 ,\n",
       "        0.32089502, 0.32355608, 0.33426354, 0.33695886, 0.3450756 ,\n",
       "        0.35320709, 0.35595919, 0.35872953, 0.36150064, 0.36427375,\n",
       "        0.36709728, 0.36996261, 0.37284376, 0.37573334, 0.37864841,\n",
       "        0.38159565, 0.39352154, 0.39668621, 0.39988222, 0.40309471,\n",
       "        0.4095773 , 0.41282123, 0.41607217, 0.4193462 , 0.42262267,\n",
       "        0.4259512 , 0.42928586, 0.43266847, 0.43605944, 0.4430919 ,\n",
       "        0.44665423, 0.45023675, 0.45390368, 0.46129869, 0.46509667,\n",
       "        0.46893821, 0.47663616, 0.48070273, 0.48477728, 0.48886862,\n",
       "        0.49297876, 0.49717326, 0.50142525, 0.50569696, 0.51428776,\n",
       "        0.51860892, 0.5230627 , 0.52757117, 0.53208579, 0.53676802,\n",
       "        0.5414739 , 0.54617978, 0.55093749, 0.55575662, 0.56071149,\n",
       "        0.56591615, 0.57169049, 0.57753213, 0.5833861 , 0.58924077,\n",
       "        0.59512243, 0.60142362, 0.61425209, 0.62736491, 0.63393028,\n",
       "        0.64058212, 0.64738981, 0.65435829, 0.66263016, 0.67142796,\n",
       "        0.68045574, 0.68993353, 0.69996682, 0.72114832, 0.73196338,\n",
       "        0.74287593, 0.75381545, 0.76511915, 0.7772768 , 0.79355704,\n",
       "        0.81107117, 0.8321923 , 0.85671068])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier() # first declare a tree\n",
    "path = clf.cost_complexity_pruning_path(data_train.iloc[:,1:], data_train.label) # then ask for all the possible values \n",
    "# of alpha to prune this tree (depends on the training set)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 2 (arbre): Trouver le meilleur niveau dÃ©lagage/ le meilleur arbre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce faire j'ai Ã©crit la fonction best_tree() qui prend en parmettre les donnÃ©es d'apprentissages et de validations ainsi que la variable cible, les diffÃ©rentes limites pour les descripteurs. Elle nous renvoie tableau (contenant les alphas, les scores sur le train et les validations) et le meilleur arbre(celui avec la meilleur perfomance en validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_tree(data_train,data_valid,Y,deb,limit):\n",
    "    result=pd.DataFrame()\n",
    "    ccp_alphas_train = []\n",
    "    score_train = []\n",
    "    score_valid = []\n",
    "\n",
    "    for i in range (len(ccp_alphas)):\n",
    "        dt_pruned_train = tree.DecisionTreeClassifier(ccp_alpha=path.ccp_alphas[i]).fit(data_train.iloc[:,deb:limit], data_train[Y])\n",
    "        ccp=path.ccp_alphas[i]\n",
    "        data_train.columns = data_train.columns.astype(str)\n",
    "        data_valid.columns = data_valid.columns.astype(str)\n",
    "        score_t=dt_pruned_train.score(data_train.iloc[:,deb:limit], data_train[Y])\n",
    "        score_v=dt_pruned_train.score(data_valid.iloc[:,deb:limit], data_valid[Y])\n",
    "        ccp_alphas_train.append(ccp) \n",
    "        score_train.append(score_t)\n",
    "        score_valid.append(score_v)\n",
    "    \n",
    "    result['ccp_alpha']= ccp_alphas_train\n",
    "    result['score_train']= score_train \n",
    "    result['score_valid']= score_valid\n",
    "    best_index = result['score_valid'].idxmax()\n",
    "    print(best_index)\n",
    "    best_tree=dt_pruned_train = tree.DecisionTreeClassifier(ccp_alpha=path.ccp_alphas[best_index]).fit(data_train.iloc[:,deb:limit], data_train[Y])\n",
    "    return result,best_tree\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     ccp_alpha  score_train  score_valid\n",
       " 0     0.000000     1.000000     0.494118\n",
       " 1     0.000796     0.998319     0.541176\n",
       " 2     0.000818     0.996639     0.525490\n",
       " 3     0.000828     0.995798     0.529412\n",
       " 4     0.000830     0.995798     0.513725\n",
       " ..         ...          ...          ...\n",
       " 157   0.038381     0.154622     0.121569\n",
       " 158   0.045008     0.154622     0.121569\n",
       " 159   0.048858     0.154622     0.121569\n",
       " 160   0.052628     0.154622     0.121569\n",
       " 161   0.081649     0.154622     0.121569\n",
       " \n",
       " [162 rows x 3 columns],\n",
       " DecisionTreeClassifier(ccp_alpha=0.0007961079168509513))"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apperÃ§u=best_tree(data_train,data_valid,'label',1,data_train.shape[1])\n",
    "meilleur_arbre_elague=apperÃ§u[1]\n",
    "apperÃ§u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 3 (arbre): Calculer l'estimation de l'erreur de gÃ©nÃ©ralisation de l'arbre choisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4901960784313726"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_gen_arbre= 1-meilleur_arbre_elague.score(data_test.iloc[:,1:data_train.shape[1]], data_test['label'])\n",
    "err_gen_arbre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons une estimation de l'erreur de gÃ©nÃ©ralisation (plutÃ´t forte) de 47,8% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrÃ©diction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predict=meilleur_arbre_elague.predict(competition.iloc[:,0:competition.shape[1]])\n",
    "# we put this predictions in a DataFrame with the right format expected by kaggle\n",
    "df = pd.DataFrame(np.arange(1,501), columns=['Id'])\n",
    "df['label'] = predict\n",
    "\n",
    "# then save it to a csv file\n",
    "df.to_csv('myfirstsubmission_tree.csv', index=False)\n",
    "# You should now have a csv file on your working directory\n",
    "# Go on Kaggle website, join the competition and drag this file into 'Submit predictions'. You should have a score\n",
    "# This score might not be high because we have just done random predictions\n",
    "# but when you'll design classifiers and make more clever predictions you will improve your score\n",
    "# Later, when you'll have found an interesting classifier for each family, you have to predict the competition set\n",
    "# with this classifier, put these predictions into a vector (like pred above) and apply the same procedure as\n",
    "# in the previous cell\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 1(SVM): Initialisation du modÃ¨le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec toutes les donnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1000, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1000, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1000, kernel='linear')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm1 = svm.SVC(C = 1000, kernel = 'linear')\n",
    "# here SVC stands for Support Vector Classification (there are other kinds of SVM),and we ask for a linear kernel\n",
    "# The parameter C is set to 1000\n",
    "\n",
    "model_svm1.fit(dataset.iloc[:,1:], dataset.label)\n",
    "# here we ask to fit the model using the features (x1 and x2) and the target (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec les donnÃ©es d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = svm.SVC(C = 1, kernel = 'linear').fit(data_train.iloc[:, 1:1024], data_train.label)\n",
    "# The parameter C is set to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score train = 1.0\n",
      "Le score valid = 0.6784313725490196\n",
      "Le score test = 0.6784313725490196\n"
     ]
    }
   ],
   "source": [
    "score_train_svm = model_svm.score(data_train.iloc[:, 1:1024], data_train.label)\n",
    "score_valid_svm = model_svm.score(data_valid.iloc[:, 1:1024], data_valid.label)\n",
    "score_test_svm = model_svm.score(data_valid.iloc[:, 1:1024], data_valid.label)\n",
    "print(\"Le score train = \"+str(score_train_svm))\n",
    "print(\"Le score valid = \"+str(score_valid_svm))\n",
    "print(\"Le score test = \" + str(score_test_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 2 (SVM): Trouver le meilleur C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "c_list=[0.01, 0.05, 1, 5, 10, 50, 100, 500, 1000]\n",
    "def svm_model(data_train, data_valid, kernel):\n",
    "    result = pd.DataFrame()\n",
    "    mod = []\n",
    "    score_train_svm = []\n",
    "    score_valid_svm = []\n",
    "    for i in c_list:\n",
    "        model = svm.SVC(C=i, kernel=kernel).fit(data_train.iloc[:, 1:1025], data_train.label)\n",
    "        mod.append(model)\n",
    "        score_t = model.score(data_train.iloc[:, 1:1025], data_train.label)\n",
    "        score_v = model.score(data_valid.iloc[:, 1:1025], data_valid.label)\n",
    "        score_train_svm.append(score_t)\n",
    "        score_valid_svm.append(score_v)\n",
    "    result['score_train'] = score_train_svm\n",
    "    result['score_validation'] = score_valid_svm\n",
    "    result['model'] = mod\n",
    "    best_index = result['score_validation'].idxmax()\n",
    "    return result, result['model'][best_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "c_list=[0.01, 0.05, 1, 5, 10, 50, 100, 500, 1000]\n",
    "def svm_model_no_lin(data_train, data_valid, kernel, gamma=None):\n",
    "    result = pd.DataFrame()\n",
    "    mod = []\n",
    "    score_train_svm = []\n",
    "    score_valid_svm = []\n",
    "    for i in c_list:\n",
    "        model = svm.SVC(C=i, kernel=kernel, gamma=gamma).fit(data_train.iloc[:, 1:1025], data_train.label)\n",
    "        mod.append(model)\n",
    "        score_t = model.score(data_train.iloc[:, 1:1025], data_train.label)\n",
    "        score_v = model.score(data_valid.iloc[:, 1:1025], data_valid.label)\n",
    "        score_train_svm.append(score_t)\n",
    "        score_valid_svm.append(score_v)\n",
    "    result['score_train'] = score_train_svm\n",
    "    result['score_validation'] = score_valid_svm\n",
    "    result['model'] = mod\n",
    "    best_index = result['score_validation'].idxmax()\n",
    "    return result, result['model'][best_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2313725490196078"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=svm_model(data_train,data_valid,'linear')\n",
    "err_gen_svm_linear = 1-res[1].score(data_test.iloc[:, 1:1025], data_test.label)\n",
    "err_gen_svm_linear"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#model_svm = svm.SVC(C = 1, kernel = 'linear').fit(data_train.iloc[:,1:], data_train.label)\n",
    "model_svm = test[1]\n",
    "svm_predict=model_svm.predict(competition.iloc[:,0:1024])\n",
    "# we put this predictions in a DataFrame with the right format expected by kaggle\n",
    "df = pd.DataFrame(np.arange(1,501), columns=['Id'])\n",
    "df['label'] = svm_predict\n",
    "\n",
    "# then save it to a csv file\n",
    "df.to_csv('myfirstsubmission_linear_svm.csv', index=False)\n",
    "# You should now have a csv file on your working directory\n",
    "# Go on Kaggle website, join the competition and drag this file into 'Submit predictions'. You should have a score\n",
    "# This score might not be high because we have just done random predictions\n",
    "# but when you'll design classifiers and make more clever predictions you will improve your score\n",
    "# Later, when you'll have found an interesting classifier for each family, you have to predict the competition set\n",
    "# with this classifier, put these predictions into a vector (like pred above) and apply the same procedure as\n",
    "# in the previous cell\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non_lineraire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   score_train  score_validation        model\n",
       " 0     0.154622          0.121569  SVC(C=0.01)\n",
       " 1     0.221008          0.160784  SVC(C=0.05)\n",
       " 2     0.974790          0.792157     SVC(C=1)\n",
       " 3     1.000000          0.819608     SVC(C=5)\n",
       " 4     1.000000          0.819608    SVC(C=10)\n",
       " 5     1.000000          0.819608    SVC(C=50)\n",
       " 6     1.000000          0.819608   SVC(C=100)\n",
       " 7     1.000000          0.819608   SVC(C=500)\n",
       " 8     1.000000          0.819608  SVC(C=1000),\n",
       " SVC(C=5))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G= [0.01, 0.1, 1, 5]\n",
    "gaussien=svm_model_no_lin(data_train,data_valid,'rbf','scale')\n",
    "gaussien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14901960784313728"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = svm.SVC(C=6, kernel='rbf').fit(data_train.iloc[:, 1:1025], data_train.label)\n",
    "err_gen_svm_rbf = 1-gaussien[1].score(data_test.iloc[:, 1:1025], data_test.label)\n",
    "err_gen_svm_rbf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "svm_predict_gauss=gaussien[1].predict(competition.iloc[:,:])\n",
    "# we put this predictions in a DataFrame with the right format expected by kaggle\n",
    "df = pd.DataFrame(np.arange(1,501), columns=['Id'])\n",
    "df['label'] = svm_predict_gauss\n",
    "\n",
    "# then save it to a csv file\n",
    "df.to_csv('myfourthsubmission_gaussien_svm.csv', index=False)\n",
    "# You should now have a csv file on your working directory\n",
    "# Go on Kaggle website, join the competition and drag this file into 'Submit predictions'. You should have a score\n",
    "# This score might not be high because we have just done random predictions\n",
    "# but when you'll design classifiers and make more clever predictions you will improve your score\n",
    "# Later, when you'll have found an interesting classifier for each family, you have to predict the competition set\n",
    "# with this classifier, put these predictions into a vector (like pred above) and apply the same procedure as\n",
    "# in the previous cell\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   score_train  score_validation                       model\n",
       " 0     0.154622          0.121569  SVC(C=0.01, kernel='poly')\n",
       " 1     0.195798          0.149020  SVC(C=0.05, kernel='poly')\n",
       " 2     0.959664          0.709804     SVC(C=1, kernel='poly')\n",
       " 3     0.997479          0.768627     SVC(C=5, kernel='poly')\n",
       " 4     1.000000          0.772549    SVC(C=10, kernel='poly')\n",
       " 5     1.000000          0.776471    SVC(C=50, kernel='poly')\n",
       " 6     1.000000          0.776471   SVC(C=100, kernel='poly')\n",
       " 7     1.000000          0.776471   SVC(C=500, kernel='poly')\n",
       " 8     1.000000          0.776471  SVC(C=1000, kernel='poly'),\n",
       " SVC(C=50, kernel='poly'))"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_poly=svm_model(data_train,data_valid,'poly')\n",
    "model_poly=test_poly[1]\n",
    "test_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2196078431372549"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_gen_svm_poly = 1-model_poly.score(data_test.iloc[:, 1:1025], data_test.label)\n",
    "err_gen_svm_poly"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "svm_predict_poly=model_poly.predict(competition.iloc[:,:])\n",
    "# we put this predictions in a DataFrame with the right format expected by kaggle\n",
    "df = pd.DataFrame(np.arange(1,501), columns=['Id'])\n",
    "df['label'] = svm_predict_poly\n",
    "\n",
    "# then save it to a csv file\n",
    "df.to_csv('myfirstsubmission_poly_svm.csv', index=False)\n",
    "# You should now have a csv file on your working directory\n",
    "# Go on Kaggle website, join the competition and drag this file into 'Submit predictions'. You should have a score\n",
    "# This score might not be high because we have just done random predictions\n",
    "# but when you'll design classifiers and make more clever predictions you will improve your score\n",
    "# Later, when you'll have found an interesting classifier for each family, you have to predict the competition set\n",
    "# with this classifier, put these predictions into a vector (like pred above) and apply the same procedure as\n",
    "# in the previous cell\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'erreur de gÃ©nÃ©ralisation la plus faible est celle du SVM avec en paramÃ¨tre C=5 et de noyau gaussien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest-neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 1(knn): Initialisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_n = KNeighborsClassifier(n_neighbors=1) # this initializes a knn for k = 1\n",
    "n_n.fit(data_train.iloc[:,1:],data_train.label)\n",
    "# here we fit this knn by giving the features of all the\n",
    "# examples of the training set (columns 1 to last) and their labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un aperÃ§u des perfomances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sur le data_train 1.0\n",
      "Sur le data_valid 0.7490196078431373\n",
      "Sur le data_test 0.7294117647058823\n"
     ]
    }
   ],
   "source": [
    "perf_sur_train= n_n.score(data_train.iloc[:,1:],data_train.label)\n",
    "perf_sur_val= n_n.score(data_valid.iloc[:,1:],data_valid.label)\n",
    "perf_sur_test= n_n.score(data_test.iloc[:,1:],data_test.label)\n",
    "\n",
    "print(\"Sur le data_train \"+ str(perf_sur_train))\n",
    "print(\"Sur le data_valid \"+ str(perf_sur_val))\n",
    "print(\"Sur le data_test \"+ str(perf_sur_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 2 (knn):  Trouver le nombre de vosins optimal pour prÃ©dire les donnÃ©es de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce faire j'ai Ã©crit la fonction knn() qui prend en paramÃ¨tre les donnÃ©es d'apprentissages et de validations ainsi que la variable cible, les diffÃ©rentes limites pour les descripteurs. Elle nous renvoie tableau (les scores sur les validations, ainsi que les modÃ¨les qui y sont associÃ©s) et le meilleur modÃ¨le(celui avec la meilleur perfomance en validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    score validation                             neighbour\n",
       " 0           0.749020   KNeighborsClassifier(n_neighbors=1)\n",
       " 1           0.647059   KNeighborsClassifier(n_neighbors=2)\n",
       " 2           0.682353   KNeighborsClassifier(n_neighbors=3)\n",
       " 3           0.650980   KNeighborsClassifier(n_neighbors=4)\n",
       " 4           0.666667                KNeighborsClassifier()\n",
       " ..               ...                                   ...\n",
       " 94          0.407843  KNeighborsClassifier(n_neighbors=95)\n",
       " 95          0.400000  KNeighborsClassifier(n_neighbors=96)\n",
       " 96          0.400000  KNeighborsClassifier(n_neighbors=97)\n",
       " 97          0.396078  KNeighborsClassifier(n_neighbors=98)\n",
       " 98          0.400000  KNeighborsClassifier(n_neighbors=99)\n",
       " \n",
       " [99 rows x 2 columns],\n",
       " KNeighborsClassifier(n_neighbors=1))"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def knn(mnist_train,mnist_valid,Y,deb,fin):\n",
    "    result= pd.DataFrame()\n",
    "    neighbour=[]\n",
    "    score=[]\n",
    "    for i in range (1,100):\n",
    "        mnist_train.columns = mnist_train.columns.astype(str)\n",
    "        mnist_valid.columns = mnist_valid.columns.astype(str)\n",
    "        n_n = KNeighborsClassifier(n_neighbors=i)\n",
    "        neighbour.append(n_n.fit(mnist_train.iloc[:,deb:fin],mnist_train[Y]))\n",
    "        n_n_score_valid=n_n.score(mnist_valid.iloc[:,deb:fin], mnist_valid[Y])\n",
    "        score.append(n_n_score_valid)\n",
    "\n",
    "    result['score validation']= score\n",
    "    result['neighbour']= neighbour\n",
    "    best_index = result['score validation'].idxmax()\n",
    "    best_neighbour= result['neighbour'][best_index]\n",
    "    knn_final=best_neighbour.fit(mnist_train.iloc[:,deb:fin],mnist_train.label)\n",
    "    return result,knn_final\n",
    "\n",
    "test=knn(data_train,data_valid,'label',1,data_train.shape[1])\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 3 (knn)= Calculer l'erreur de gÃ©nÃ©ralisation du modÃ¨le choisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2705882352941177"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_gen_arbre= 1-test[1].score(data_test.iloc[:,1:data_train.shape[1]], data_test['label'])\n",
    "err_gen_arbre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons une estimation de l'erreur de gÃ©nÃ©ralisation pour les l'agorithme des knn 27%. Cette erreur est meilleure que l'erreur de gÃ©nÃ©ralisation des arbres "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalculer le modÃ¨le en excluant le 1-ppv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_more_tran_1(mnist_train,mnist_valid,Y,deb,fin):\n",
    "    result= pd.DataFrame()\n",
    "    neighbour=[]\n",
    "    score=[]\n",
    "    for i in range (2,100):\n",
    "        mnist_train.columns = mnist_train.columns.astype(str)\n",
    "        mnist_valid.columns = mnist_valid.columns.astype(str)\n",
    "        n_n = KNeighborsClassifier(n_neighbors=i)\n",
    "        neighbour.append(n_n.fit(mnist_train.iloc[:,deb:fin],mnist_train[Y]))\n",
    "        n_n_score_valid=n_n.score(mnist_valid.iloc[:,deb:fin], mnist_valid[Y])\n",
    "        score.append(n_n_score_valid)\n",
    "\n",
    "    result['score validation']= score\n",
    "    result['neighbour']= neighbour\n",
    "    best_index = result['score validation'].idxmax()\n",
    "    best_neighbour= result['neighbour'][best_index]\n",
    "    knn_final=best_neighbour.fit(mnist_train.iloc[:,deb:fin],mnist_train.label)\n",
    "    return result,knn_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    score validation                             neighbour\n",
       " 0           0.647059   KNeighborsClassifier(n_neighbors=2)\n",
       " 1           0.682353   KNeighborsClassifier(n_neighbors=3)\n",
       " 2           0.650980   KNeighborsClassifier(n_neighbors=4)\n",
       " 3           0.666667                KNeighborsClassifier()\n",
       " 4           0.639216   KNeighborsClassifier(n_neighbors=6)\n",
       " ..               ...                                   ...\n",
       " 93          0.407843  KNeighborsClassifier(n_neighbors=95)\n",
       " 94          0.400000  KNeighborsClassifier(n_neighbors=96)\n",
       " 95          0.400000  KNeighborsClassifier(n_neighbors=97)\n",
       " 96          0.396078  KNeighborsClassifier(n_neighbors=98)\n",
       " 97          0.400000  KNeighborsClassifier(n_neighbors=99)\n",
       " \n",
       " [98 rows x 2 columns],\n",
       " KNeighborsClassifier(n_neighbors=3))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_sans_1ppv=knn_more_tran_1(data_train,data_valid,'label',1,data_train.shape[1])\n",
    "knn_sans_1ppv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3019607843137255"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_gen_arbre= 1-knn_sans_1ppv[1].score(data_test.iloc[:,1:data_train.shape[1]], data_test['label'])\n",
    "err_gen_arbre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrÃ©diction avec 1-ppv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predict=test[1].predict(competition.iloc[:,0:competition.shape[1]])\n",
    "# we put this predictions in a DataFrame with the right format expected by kaggle\n",
    "df = pd.DataFrame(np.arange(1,501), columns=['Id'])\n",
    "df['label'] = predict\n",
    "\n",
    "# then save it to a csv file\n",
    "df.to_csv('myfirstsubmission_knn.csv', index=False)\n",
    "# You should now have a csv file on your working directory\n",
    "# Go on Kaggle website, join the competition and drag this file into 'Submit predictions'. You should have a score\n",
    "# This score might not be high because we have just done random predictions\n",
    "# but when you'll design classifiers and make more clever predictions you will improve your score\n",
    "# Later, when you'll have found an interesting classifier for each family, you have to predict the competition set\n",
    "# with this classifier, put these predictions into a vector (like pred above) and apply the same procedure as\n",
    "# in the previous cell\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrÃ©diction sans 1-ppv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predict=knn_sans_1ppv[1].predict(competition.iloc[:,0:competition.shape[1]])\n",
    "# we put this predictions in a DataFrame with the right format expected by kaggle\n",
    "df = pd.DataFrame(np.arange(1,501), columns=['Id'])\n",
    "df['label'] = predict\n",
    "\n",
    "# then save it to a csv file\n",
    "df.to_csv('myfirstsubmission_knn_without_1ppv.csv', index=False)\n",
    "# You should now have a csv file on your working directory\n",
    "# Go on Kaggle website, join the competition and drag this file into 'Submit predictions'. You should have a score\n",
    "# This score might not be high because we have just done random predictions\n",
    "# but when you'll design classifiers and make more clever predictions you will improve your score\n",
    "# Later, when you'll have found an interesting classifier for each family, you have to predict the competition set\n",
    "# with this classifier, put these predictions into a vector (like pred above) and apply the same procedure as\n",
    "# in the previous cell\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 1: Initiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f = RandomForestClassifier(n_estimators=10) # this initializes a random forest with 10 trees\n",
    "r_f.fit(data_train.iloc[:,1:],data_train.label) \n",
    "# here we fit this random forest by giving the features of all the\n",
    "# examples of the training set (columns 1 to last) and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6509803921568628"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_score_train=r_f.score(data_train.iloc[:,1:data_train.shape[1]], data_train.label)\n",
    "r_f_score_valid=r_f.score(data_valid.iloc[:,1:data_valid.shape[1]], data_valid.label)\n",
    "\n",
    "r_f_score_train\n",
    "r_f_score_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 2: Trouver le meilleur nombre d'arbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest(mnist_train,mnist_valid,Y,deb):\n",
    "    result= pd.DataFrame()\n",
    "    tree=[]\n",
    "    score=[]\n",
    "    for i in range (1,100):\n",
    "        mnist_train.columns = mnist_train.columns.astype(str)\n",
    "        mnist_valid.columns = mnist_valid.columns.astype(str)\n",
    "        r_f = RandomForestClassifier(n_estimators=i) # this initializes a random forest\n",
    "        tree.append(r_f.fit(mnist_train.iloc[:,deb:],mnist_train[Y]))\n",
    "        r_f_score_valid=r_f.score(mnist_valid.iloc[:,deb:mnist_valid.shape[1]], mnist_valid[Y])\n",
    "        score.append(r_f_score_valid)\n",
    "\n",
    "    result['score']= score\n",
    "    result['tree']= tree\n",
    "    best_index = result['score'].idxmax()\n",
    "    best_forest = RandomForestClassifier(n_estimators=best_index)\n",
    "    forest=best_forest.fit(mnist_train.iloc[:,deb:],mnist_train.label)\n",
    "    return result,forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=79)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=79)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=79)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=forest(data_train,data_valid,'label',1)[1]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19215686274509802"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest_error=1-result.score(data_test.iloc[:,1:data_test.shape[1]], data_test.label)\n",
    "best_forest_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression logistique simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression().fit(data_train.iloc[:,1:], data_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29803921568627456"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_error=1-lr_model.score(data_test.iloc[:,1:data_test.shape[1]], data_test.label)\n",
    "best_lr_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression multinomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree = 2) \n",
    "X2_train_poly = pd.DataFrame(poly.fit_transform(data_train.iloc[:,1:]))\n",
    "X2_valid_poly = pd.DataFrame(poly.fit_transform(data_valid.iloc[:,1:]))\n",
    "X2_test_poly = pd.DataFrame(poly.fit_transform(data_test.iloc[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = LogisticRegression(multi_class='multinomial', max_iter=1000).fit(X2_train_poly.iloc[:,0:], data_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial')"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14117647058823535"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_multi_error_X2=1-mc_model.score(X2_test_poly.iloc[:,0:], data_test.label)\n",
    "lr_multi_error_X2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 : using HOG representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hog(row, ori, cell, labels = True):\n",
    "    if labels:\n",
    "        return(pd.Series(hog(row.iloc[1:].to_numpy().reshape(32,32,1), orientations=ori, pixels_per_cell=(cell, cell), cells_per_block=(3,3), channel_axis=2)))\n",
    "    else:\n",
    "        return(pd.Series(hog(row.to_numpy().reshape(32,32,1), orientations=ori, pixels_per_cell=(cell, cell), cells_per_block=(3,3), channel_axis=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_competition=competition.apply(my_hog, axis=1, args=(12,7,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_train = data_train.apply(my_hog, axis=1, args=(12,7))\n",
    "hog_valid= data_valid.apply(my_hog, axis=1, args=(12,7))\n",
    "hog_test = data_test.apply(my_hog, axis=1, args=(12,7))\n",
    "hog_train['label'] = data_train.label\n",
    "hog_valid['label'] = data_valid.label\n",
    "hog_test['label'] = data_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.284661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows Ã— 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7        8    9  ...  279  \\\n",
       "248   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0   \n",
       "436   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0   \n",
       "1507  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0   \n",
       "1134  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0   \n",
       "1291  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...      ...  ...  ...  ...   \n",
       "361   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0   \n",
       "710   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0   \n",
       "440   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.03104  0.0  ...  0.0   \n",
       "175   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0   \n",
       "1147  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0   \n",
       "\n",
       "           280  281       282  283       284  285  286  287  label  \n",
       "248   0.095946  0.0  0.067844  0.0  0.095946  0.0  0.0  0.0      6  \n",
       "436   0.147278  0.0  0.304850  0.0  0.196371  0.0  0.0  0.0     16  \n",
       "1507  0.284661  0.0  0.232797  0.0  0.000000  0.0  0.0  0.0     16  \n",
       "1134  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0      1  \n",
       "1291  0.000000  0.0  0.000000  0.0  0.114753  0.0  0.0  0.0     12  \n",
       "...        ...  ...       ...  ...       ...  ...  ...  ...    ...  \n",
       "361   0.268452  0.0  0.268452  0.0  0.000000  0.0  0.0  0.0     22  \n",
       "710   0.052559  0.0  0.074329  0.0  0.000000  0.0  0.0  0.0     12  \n",
       "440   0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0     22  \n",
       "175   0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0      6  \n",
       "1147  0.000000  0.0  0.000000  0.0  0.062564  0.0  0.0  0.0     18  \n",
       "\n",
       "[1190 rows x 289 columns]"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_train.columns = hog_train.columns.astype(str)\n",
    "hog_valid.columns = hog_valid.columns.astype(str)\n",
    "hog_test.columns = hog_test.columns.astype(str)\n",
    "hog_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin=hog_train.shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier() # first declare a tree\n",
    "path = clf.cost_complexity_pruning_path(hog_train.iloc[:,:fin], hog_train.label) # then ask for all the possible values \n",
    "# of alpha to prune this tree (depends on the training set)\n",
    "path\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     ccp_alpha  score_train  score_valid\n",
       " 0     0.000000     1.000000     0.694118\n",
       " 1     0.000796     0.998319     0.694118\n",
       " 2     0.000818     0.996639     0.705882\n",
       " 3     0.000830     0.995798     0.729412\n",
       " 4     0.000830     0.994958     0.701961\n",
       " ..         ...          ...          ...\n",
       " 158   0.038381     0.463025     0.470588\n",
       " 159   0.045008     0.415966     0.427451\n",
       " 160   0.048858     0.365546     0.356863\n",
       " 161   0.052628     0.275630     0.223529\n",
       " 162   0.081649     0.154622     0.121569\n",
       " \n",
       " [163 rows x 3 columns],\n",
       " DecisionTreeClassifier(ccp_alpha=0.0015126050420168071))"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apperÃ§u=best_tree(hog_train,hog_valid,'label',0,fin)\n",
    "meilleur_arbre_elague=apperÃ§u[1]\n",
    "apperÃ§u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2431372549019608"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree_hog_error=1-meilleur_arbre_elague.score(hog_test.iloc[:,0:fin], hog_test.label)\n",
    "best_tree_hog_error"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predict=meilleur_arbre_elague.predict(hog_competition.iloc[:,:])\n",
    "# we put this predictions in a DataFrame with the right format expected by kaggle\n",
    "df = pd.DataFrame(np.arange(1,501), columns=['Id'])\n",
    "df['label'] = predict\n",
    "# then save it to a csv file\n",
    "df.to_csv('hog_tree_submission.csv', index=False)\n",
    "# You should now have a csv file on your working directory\n",
    "# Go on Kaggle website, join the competition and drag this file into 'Submit predictions'. You should have a score\n",
    "# This score might not be high because we have just done random predictions\n",
    "# but when you'll design classifiers and make more clever predictions you will improve your score\n",
    "# Later, when you'll have found an interesting classifier for each family, you have to predict the competition set\n",
    "# with this classifier, put these predictions into a vector (like pred above) and apply the same procedure as\n",
    "# in the previous cell\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ================ Fonctions SVM pour HOG ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "c_list=[0.01, 0.05, 1, 5, 10, 50, 100, 500, 1000]\n",
    "def svm_model_hog_lin(data_train, data_valid):\n",
    "    result = pd.DataFrame()\n",
    "    mod = []\n",
    "    score_train_svm = []\n",
    "    score_valid_svm = []\n",
    "    for i in c_list:\n",
    "        model = svm.SVC(C=i, kernel='linear').fit(data_train.iloc[:,:fin], hog_train.label)\n",
    "        mod.append(model)\n",
    "        score_t = model.score(data_train.iloc[:,:fin], hog_train.label)\n",
    "        score_v = model.score(data_valid.iloc[:,:fin], hog_valid.label)\n",
    "        score_train_svm.append(score_t)\n",
    "        score_valid_svm.append(score_v)\n",
    "    result['score_train'] = score_train_svm\n",
    "    result['score_validation'] = score_valid_svm\n",
    "    result['model'] = mod\n",
    "    best_index = result['score_validation'].idxmax()\n",
    "    return result, result['model'][best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "c_list=[0.01, 0.05, 1, 5, 10, 50, 100, 500, 1000]\n",
    "def svm_model_hog_gauss(data_train, data_valid, kernel,fin, gamma=None):\n",
    "    result = pd.DataFrame()\n",
    "    mod = []\n",
    "    score_train_svm = []\n",
    "    score_valid_svm = []\n",
    "    for i in c_list:\n",
    "        #if gamma is None:\n",
    "        model = svm.SVC(C=i, kernel=kernel, gamma=gamma).fit(data_train.iloc[:, 0:fin], data_train.label)\n",
    "        #else:\n",
    "            #model = svm.SVC(C=i, kernel=kernel, gamma=gamma).fit(data_train.iloc[:, 1:1025], data_train.label)\n",
    "        mod.append(model)\n",
    "        score_t = model.score(data_train.iloc[:, :fin], data_train.label)\n",
    "        score_v = model.score(data_valid.iloc[:, :fin], data_valid.label)\n",
    "        score_train_svm.append(score_t)\n",
    "        score_valid_svm.append(score_v)\n",
    "    result['score_train'] = score_train_svm\n",
    "    result['score_validation'] = score_valid_svm\n",
    "    result['model'] = mod\n",
    "    best_index = result['score_validation'].idxmax()\n",
    "    return result, result['model'][best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "c_list=[0.01, 0.05, 1, 5, 10, 50, 100, 500, 1000]\n",
    "d_list=[0.01, 0.1, 1, 5]\n",
    "def svm_model_hog_poly(data_train, data_valid, kernel,fin,deg):\n",
    "    result = pd.DataFrame()\n",
    "    mod = []\n",
    "    score_train_svm = []\n",
    "    score_valid_svm = []\n",
    "    for i in c_list:\n",
    "            model = svm.SVC(C=i, kernel=kernel, degree=deg).fit(data_train.iloc[:, 0:fin], data_train.label)\n",
    "            mod.append(model)\n",
    "            score_t = model.score(data_train.iloc[:, :fin], data_train.label)\n",
    "            score_v = model.score(data_valid.iloc[:, :fin], data_valid.label)\n",
    "            score_train_svm.append(score_t)\n",
    "            score_valid_svm.append(score_v)\n",
    "    result['score_train'] = score_train_svm\n",
    "    result['score_validation'] = score_valid_svm\n",
    "    result['model'] = mod\n",
    "    best_index = result['score_validation'].idxmax()\n",
    "    return result, result['model'][best_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ================ Fin Fonctions SVM pour HOG ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hog_model=svm_model_hog_lin(hog_train,hog_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10588235294117643"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_error_svm_lin=1-svm_hog_model[1].score(hog_test.iloc[:,:fin], hog_test.label)\n",
    "hog_error_svm_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hog_gaussien_model=svm_model_hog_gauss(hog_train,hog_valid,'rbf',fin,'scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   score_train  score_validation        model\n",
       " 0     0.303361          0.247059  SVC(C=0.01)\n",
       " 1     0.726891          0.686275  SVC(C=0.05)\n",
       " 2     1.000000          1.000000     SVC(C=1)\n",
       " 3     1.000000          1.000000     SVC(C=5)\n",
       " 4     1.000000          1.000000    SVC(C=10)\n",
       " 5     1.000000          1.000000    SVC(C=50)\n",
       " 6     1.000000          1.000000   SVC(C=100)\n",
       " 7     1.000000          1.000000   SVC(C=500)\n",
       " 8     1.000000          1.000000  SVC(C=1000),\n",
       " SVC(C=1))"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_hog_gaussien_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_error_svm_gauss=1-svm_hog_gaussien_model[1].score(hog_test.iloc[:,:fin], hog_test.label)\n",
    "hog_error_svm_gauss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predict=svm_hog_gaussien_model[1].predict(hog_competition.iloc[:,:])\n",
    "# we put this predictions in a DataFrame with the right format expected by kaggle\n",
    "df = pd.DataFrame(np.arange(1,501), columns=['Id'])\n",
    "df['label'] = predict\n",
    "# then save it to a csv file\n",
    "df.to_csv('hog_svm_gaussien_submission_gamma_test.csv', index=False)\n",
    "# You should now have a csv file on your working directory\n",
    "# Go on Kaggle website, join the competition and drag this file into 'Submit predictions'. You should have a score\n",
    "# This score might not be high because we have just done random predictions\n",
    "# but when you'll design classifiers and make more clever predictions you will improve your score\n",
    "# Later, when you'll have found an interesting classifier for each family, you have to predict the competition set\n",
    "# with this classifier, put these predictions into a vector (like pred above) and apply the same procedure as\n",
    "# in the previous cell\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hog_poly_model=svm_model_hog_poly(hog_train,hog_valid,'poly',fin,deg=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   score_train  score_validation                                 model\n",
       " 0     0.294958          0.258824  SVC(C=0.01, degree=5, kernel='poly')\n",
       " 1     0.830252          0.811765  SVC(C=0.05, degree=5, kernel='poly')\n",
       " 2     0.988235          0.905882     SVC(C=1, degree=5, kernel='poly')\n",
       " 3     0.999160          0.901961     SVC(C=5, degree=5, kernel='poly')\n",
       " 4     1.000000          0.901961    SVC(C=10, degree=5, kernel='poly')\n",
       " 5     1.000000          0.901961    SVC(C=50, degree=5, kernel='poly')\n",
       " 6     1.000000          0.901961   SVC(C=100, degree=5, kernel='poly')\n",
       " 7     1.000000          0.901961   SVC(C=500, degree=5, kernel='poly')\n",
       " 8     1.000000          0.901961  SVC(C=1000, degree=5, kernel='poly'),\n",
       " SVC(C=1, degree=5, kernel='poly'))"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_hog_poly_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07450980392156858"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_error_svm_poly=1-svm_hog_poly_model[1].score(hog_test.iloc[:,:fin], hog_test.label)\n",
    "hog_error_svm_poly"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predict=svm_hog_poly_model[1].predict(hog_competition.iloc[:,:])\n",
    "# we put this predictions in a DataFrame with the right format expected by kaggle\n",
    "df = pd.DataFrame(np.arange(1,501), columns=['Id'])\n",
    "df['label'] = predict\n",
    "# then save it to a csv file\n",
    "df.to_csv('hog_svm_poly_submission_3.csv', index=False)\n",
    "# You should now have a csv file on your working directory\n",
    "# Go on Kaggle website, join the competition and drag this file into 'Submit predictions'. You should have a score\n",
    "# This score might not be high because we have just done random predictions\n",
    "# but when you'll design classifiers and make more clever predictions you will improve your score\n",
    "# Later, when you'll have found an interesting classifier for each family, you have to predict the competition set\n",
    "# with this classifier, put these predictions into a vector (like pred above) and apply the same procedure as\n",
    "# in the previous cell\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest-neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_hog=knn_more_tran_1(hog_train,hog_valid,'label',0,fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    score validation                             neighbour\n",
       " 0           0.862745   KNeighborsClassifier(n_neighbors=2)\n",
       " 1           0.878431   KNeighborsClassifier(n_neighbors=3)\n",
       " 2           0.890196   KNeighborsClassifier(n_neighbors=4)\n",
       " 3           0.874510                KNeighborsClassifier()\n",
       " 4           0.874510   KNeighborsClassifier(n_neighbors=6)\n",
       " ..               ...                                   ...\n",
       " 93          0.819608  KNeighborsClassifier(n_neighbors=95)\n",
       " 94          0.819608  KNeighborsClassifier(n_neighbors=96)\n",
       " 95          0.819608  KNeighborsClassifier(n_neighbors=97)\n",
       " 96          0.815686  KNeighborsClassifier(n_neighbors=98)\n",
       " 97          0.811765  KNeighborsClassifier(n_neighbors=99)\n",
       " \n",
       " [98 rows x 2 columns],\n",
       " KNeighborsClassifier(n_neighbors=4))"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10196078431372546"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_error_KNN_1=1-knn_hog[1].score(hog_test.iloc[:,0:fin], hog_test.label)\n",
    "hog_error_KNN_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>423</th>\n",
       "      <th>424</th>\n",
       "      <th>425</th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "      <th>431</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows Ã— 433 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...       423  424  \\\n",
       "248   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.067844  0.0   \n",
       "436   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.304850  0.0   \n",
       "1507  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.232797  0.0   \n",
       "1134  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000  0.0   \n",
       "1291  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...  ...   \n",
       "361   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.268452  0.0   \n",
       "710   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.074329  0.0   \n",
       "440   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000  0.0   \n",
       "175   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000  0.0   \n",
       "1147  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000  0.0   \n",
       "\n",
       "      425       426  427  428  429  430  431  label  \n",
       "248   0.0  0.095946  0.0  0.0  0.0  0.0  0.0      6  \n",
       "436   0.0  0.196371  0.0  0.0  0.0  0.0  0.0     16  \n",
       "1507  0.0  0.000000  0.0  0.0  0.0  0.0  0.0     16  \n",
       "1134  0.0  0.000000  0.0  0.0  0.0  0.0  0.0      1  \n",
       "1291  0.0  0.114753  0.0  0.0  0.0  0.0  0.0     12  \n",
       "...   ...       ...  ...  ...  ...  ...  ...    ...  \n",
       "361   0.0  0.000000  0.0  0.0  0.0  0.0  0.0     22  \n",
       "710   0.0  0.000000  0.0  0.0  0.0  0.0  0.0     12  \n",
       "440   0.0  0.000000  0.0  0.0  0.0  0.0  0.0     22  \n",
       "175   0.0  0.000000  0.0  0.0  0.0  0.0  0.0      6  \n",
       "1147  0.0  0.062564  0.0  0.0  0.0  0.0  0.0     18  \n",
       "\n",
       "[1190 rows x 433 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= pd.DataFrame()\n",
    "tree_forest=[]\n",
    "score=[]\n",
    "for i in range (1,100):\n",
    "        hog_train.columns = hog_train.columns.astype(str)\n",
    "        hog_valid.columns = hog_valid.columns.astype(str)\n",
    "        r_f = RandomForestClassifier(n_estimators=i) # this initializes a random forest\n",
    "        tree_forest.append(r_f.fit(hog_train.iloc[:,:fin],hog_train.label))\n",
    "        r_f_score_valid=r_f.score(hog_valid.iloc[:,:fin], hog_valid.label)\n",
    "        score.append(r_f_score_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['score']= score\n",
    "result['tree']= tree\n",
    "best_index = result['score'].idxmax()\n",
    "best_forest = RandomForestClassifier(n_estimators=best_index)\n",
    "forest=best_forest.fit(hog_train.iloc[:,:fin],hog_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=83)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=83)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=83)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13725490196078427"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_hog_=1-forest.score(hog_test.iloc[:,0:fin], data_test.label)\n",
    "forest_hog_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree = 2) \n",
    "X2_train_poly_hog = pd.DataFrame(poly.fit_transform(hog_train.iloc[:,:fin]))\n",
    "X2_valid_poly_hog = pd.DataFrame(poly.fit_transform(hog_valid.iloc[:,:fin]))\n",
    "X2_test_poly_hog = pd.DataFrame(poly.fit_transform(hog_test.iloc[:,:fin]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_hog_model = LogisticRegression(multi_class='multinomial', max_iter=1000).fit(X2_train_poly_hog.iloc[:,:], hog_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial')"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_hog_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10588235294117643"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_hog_multi_error_X2=1-mc_hog_model.score(X2_test_poly_hog.iloc[:,0:],hog_test.label)\n",
    "lr_hog_multi_error_X2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
